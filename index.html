<!DOCTYPE html><html lang="en"><head><link rel="preload" as="script" href="https://bit-ml.github.io/bootstrap.eb3e92c3.js"/><link rel="preload" as="script" href="https://bit-ml.github.io/templates/src/containers/Home.01bd1720.js"/><link rel="preload" as="script" href="https://bit-ml.github.io/main.7c722bc8.js"/><meta charSet="UTF-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><link href="//fonts.googleapis.com/css?family=Bitter:400" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Roboto:300,400" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Exo+2:400,600" rel="stylesheet"/><link rel="apple-touch-icon" href="icon.png"/><style data-styled-components="cDpmCw">
/* sc-component-id: sc-global-473536117 */
html{line-height:1.15;-webkit-text-size-adjust:100%;} body{margin:0;} h1{font-size:2em;margin:0.67em 0;} hr{box-sizing:content-box;height:0;overflow:visible;} pre{font-family:monospace,monospace;font-size:1em;} a{background-color:transparent;} abbr[title]{border-bottom:none;-webkit-text-decoration:underline;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted;} b,strong{font-weight:bolder;} code,kbd,samp{font-family:monospace,monospace;font-size:1em;} small{font-size:80%;} sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline;} sub{bottom:-0.25em;} sup{top:-0.5em;} figure{margin:0;} img{border-style:none;} button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0;} button,input{overflow:visible;} button,select{text-transform:none;} button,[type="button"],[type="reset"],[type="submit"]{-webkit-appearance:button;} button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0;} button:-moz-focusring,[type="button"]:-moz-focusring,[type="reset"]:-moz-focusring,[type="submit"]:-moz-focusring{outline:1px dotted ButtonText;} fieldset{padding:0.35em 0.75em 0.625em;} legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal;} progress{vertical-align:baseline;} textarea{overflow:auto;} [type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0;} [type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{height:auto;} [type="search"]{-webkit-appearance:textfield;outline-offset:-2px;} [type="search"]::-webkit-search-decoration{-webkit-appearance:none;} ::-webkit-file-upload-button{-webkit-appearance:button;font:inherit;} details{display:block;} summary{display:list-item;} template{display:none;} [hidden]{display:none;} html{box-sizing:border-box;font-size:16px;} *,*::before,*::after{box-sizing:inherit;} body{font-family:'Roboto',sans-serif;font-weight:400;font-size:16px;padding:0;background:#EDEBEB;} h1{display:block;margin:0.67em 0;}
/* sc-component-id: App__AppStyles-jGLnGW */
.cDpmCw a{-webkit-text-decoration:none;text-decoration:none;color:#108db8;font-weight:bold;} .cDpmCw nav{width:100%;background:#020100;padding:0 1rem;font-family:Roboto;text-align:right;} .cDpmCw nav a{padding:1rem;display:inline-block;font-style:normal;font-weight:500;line-height:23px;font-size:14px;text-align:right;text-transform:uppercase;color:#A8A8A8;} .cDpmCw nav a:last-child{padding-right:0;} @media (min-width:64.0625em){.cDpmCw nav{padding:0 5rem;}} .cDpmCw img{max-width:100%;}</style><style data-styled-components="dVPjPt ehEcQU jDndtc dJHxnW gNhSYZ fDWUwD doMvKk looFfB faftxq hTCVgx kLZmb gGTWSb bsszGK dWtSnV hNRwWb gTCqVT hQyaQE dvaIyb kxkinx jpxIBs jWtnNY cFmWkc fTTyYJ vJsRg eruIzS ebfeBw iQvatf fpCZLV">
/* sc-component-id: Hero-lcEsqM */
.dVPjPt{display:inline-block;width:100%;margin:0 auto;height:95vh;padding:0 1rem;background:#020100 url('./hero_avatar.jpg') no-repeat bottom;background-size:1024px;background-position:-600px bottom;} @media (min-width:64.0625em){.dVPjPt{padding:0 5rem;background-size:contain;background-position:bottom;}}
/* sc-component-id: Hero__Heading-bTunXm */
.ehEcQU{max-width:800px;font-family:'Exo 2',serif;font-style:normal;font-weight:500;font-size:36px;line-height:3rem;color:#E4E4E4;} @media (min-width:64.0625em){.ehEcQU{font-size:64px;line-height:92px;}}
/* sc-component-id: Specialty__SpecialtyWrapper-cBNbYF */
.dJHxnW{position:relative;} @media (min-width:64.0625em){.dJHxnW{max-width:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}}
/* sc-component-id: Specialty__SpecialtyPanel-hKIYws */
.gNhSYZ{background:#E6212B;overflow:hidden;} @media (min-width:64.0625em){.gNhSYZ{position:-webkit-sticky;position:sticky;top:0;height:100vh;width:38%;overflow:hidden;left:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.gNhSYZ .specItem{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-flex-shrink:1;-ms-flex-negative:1;flex-shrink:1;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}}.fDWUwD{background:#00B2CB;overflow:hidden;} @media (min-width:64.0625em){.fDWUwD{position:-webkit-sticky;position:sticky;top:0;height:100vh;width:38%;overflow:hidden;left:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.fDWUwD .specItem{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-flex-shrink:1;-ms-flex-negative:1;flex-shrink:1;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}}.doMvKk{background:#12161E;overflow:hidden;} @media (min-width:64.0625em){.doMvKk{position:-webkit-sticky;position:sticky;top:0;height:100vh;width:38%;overflow:hidden;left:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.doMvKk .specItem{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-flex-shrink:1;-ms-flex-negative:1;flex-shrink:1;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}}.looFfB{background:#C700CB;overflow:hidden;} @media (min-width:64.0625em){.looFfB{position:-webkit-sticky;position:sticky;top:0;height:100vh;width:38%;overflow:hidden;left:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.looFfB .specItem{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-flex-shrink:1;-ms-flex-negative:1;flex-shrink:1;-webkit-flex-basis:auto;-ms-flex-preferred-size:auto;flex-basis:auto;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;}}
/* sc-component-id: Specialty__Heading-hJmugM */
.faftxq{margin-top:0;font-family:'Bitter',serif;font-style:normal;font-weight:400;font-size:62px;line-height:50px;-webkit-letter-spacing:0.08em;-moz-letter-spacing:0.08em;-ms-letter-spacing:0.08em;letter-spacing:0.08em;text-transform:uppercase;color:rgba(255,255,255,0.2);} @media (min-width:64.0625em){.faftxq{position:initial;top:initial;line-height:78px;font-size:96px;margin-top:-3px;}}
/* sc-component-id: Specialty__Description-eZxbxJ */
.hTCVgx{-webkit-box-flex:10;-webkit-flex-grow:10;-ms-flex-positive:10;flex-grow:10;font-family:'Roboto',sans-serif;font-style:normal;font-weight:300;line-height:1.6rem;font-size:1.2rem;color:rgba(255,255,255,0.8);padding:0 1rem;} @media (min-width:64.0625em){.hTCVgx{padding:0 5rem;line-height:2.25rem;font-size:1.5rem;}}
/* sc-component-id: Specialty__Team-iIpdBS */
.kLZmb{font-family:Roboto;font-style:normal;font-weight:400;line-height:23px;font-size:14px;color:rgba(255,255,255,0.5);padding:0 1rem;} @media (min-width:64.0625em){.kLZmb{padding:0 5rem;}}
/* sc-component-id: Specialty__ProjectsWrapper-glhYAT */
@media (min-width:64.0625em){.gGTWSb{max-width:62%;}}
/* sc-component-id: Project-kErvvP */
@media (min-width:64.0625em){.bsszGK{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;min-height:100vh;}}
/* sc-component-id: Project__ProjectContent-ldPVeh */
.dWtSnV{display:inline-block;padding:0 1rem;} @media (min-width:64.0625em){.dWtSnV{padding:0 15rem;}}
/* sc-component-id: Project__Heading-cxYzLq */
.hNRwWb{font-family:'Exo 2',sans-serif;font-style:normal;font-weight:700;line-height:37px;font-size:22px;-webkit-letter-spacing:0.03em;-moz-letter-spacing:0.03em;-ms-letter-spacing:0.03em;letter-spacing:0.03em;text-transform:uppercase;color:#333333;}
/* sc-component-id: Project__Text-jtyfJe */
.gTCqVT{font-family:'Roboto',sans-serif;font-style:normal;font-weight:400;line-height:26px;font-size:16px;-webkit-letter-spacing:0.03em;-moz-letter-spacing:0.03em;-ms-letter-spacing:0.03em;letter-spacing:0.03em;color:#333333;}
/* sc-component-id: Project__BibList-ewVyJd */
.hQyaQE{margin-top:3rem;padding-left:0;} .hQyaQE li>a{font-weight:normal;color:inherit;}
/* sc-component-id: Project__BibItem-kCJSqY */
.dvaIyb{padding:.5rem;list-style:none;font-family:Roboto;font-style:italic;font-weight:400;line-height:20px;font-size:14px;-webkit-letter-spacing:0.03em;-moz-letter-spacing:0.03em;-ms-letter-spacing:0.03em;letter-spacing:0.03em;color:#828282;} .dvaIyb:hover{background-color:#e0dcdc;-webkit-transition:background-color 0.2s cubic-bezier(0.25,0.46,0.45,0.94);transition:background-color 0.2s cubic-bezier(0.25,0.46,0.45,0.94);}
/* sc-component-id: Project__BibAuthors-imCORI */
.jpxIBs{font-style:normal;color:#E6212B;}
/* sc-component-id: Project__BibYear-dNTgUT */
.jWtnNY{font-style:normal;}
/* sc-component-id: Bio__BioBox-eznaTq */
.fTTyYJ{margin-left:5px;margin-right:5px;-webkit-flex:1 1 350px;-ms-flex:1 1 350px;flex:1 1 350px;padding:0.6rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-transition:all 0.2s cubic-bezier(0.25,0.46,0.45,0.94);transition:all 0.2s cubic-bezier(0.25,0.46,0.45,0.94);} @supports (display:grid){.fTTyYJ{margin:0;}} @media (min-width:64.0625em){.fTTyYJ:hover{background-color:#fff;box-shadow:0px 0px 17px -4px rgba(115,108,108,1);-webkit-transform:scale(1.05);-ms-transform:scale(1.05);transform:scale(1.05);}.fTTyYJ:hover div>a{opacity:1;}}
/* sc-component-id: Bio__MediaFigure-kAfGvT */
.vJsRg{margin-right:1rem;max-width:96px;max-height:96px;border-radius:50%;border:5px solid #fff;overflow:hidden;}
/* sc-component-id: Bio__MediaBody-igRzHf */
.eruIzS{-webkit-flex:1;-ms-flex:1;flex:1;}
/* sc-component-id: Bio__Heading-ftjIRz */
.ebfeBw{font-family:'Exo 2',serif;font-style:normal;font-weight:600;line-height:27px;font-size:1rem;-webkit-letter-spacing:0.1em;-moz-letter-spacing:0.1em;-ms-letter-spacing:0.1em;letter-spacing:0.1em;text-transform:uppercase;margin:0 0 1rem 0;}
/* sc-component-id: Bio-cTLmRQ */
.iQvatf{font-family:Exo 2;font-style:normal;font-weight:normal;line-height:23px;font-size:1rem;color:#828282;margin-top:0;}
/* sc-component-id: Bio__ContactBox-bMmHPs */
.fpCZLV{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;-webkit-flex-wrap:nowrap;-ms-flex-wrap:nowrap;flex-wrap:nowrap;margin-bottom:1rem;} .fpCZLV >a{width:33.33%;text-align:center;font-weight:normal !important;color:#828282 !important;padding:0.5rem;border:1px solid #edebeb;margin-right:5px;-webkit-transition:all 0.2s cubic-bezier(0.25,0.46,0.45,0.94);transition:all 0.2s cubic-bezier(0.25,0.46,0.45,0.94);} .fpCZLV >a:hover{background-color:#edebeb;} @media (min-width:64.0625em){.fpCZLV >a{opacity:0;}}
/* sc-component-id: ResearchTeam-irfXYZ */
.cFmWkc{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;display:grid;grid-template-columns:repeat(auto-fill,minmax(350px,1fr));grid-auto-rows:minmax(150px,auto);grid-gap:3rem;padding:6rem 1rem;background:#F5F2F2;} @media (min-width:64.0625em){.cFmWkc{padding:10rem 5rem;}}</style></head><body><div id="root"><div class="App__AppStyles-jGLnGW cDpmCw" data-reactroot=""><nav><a class="active" aria-current="page" href="https://bit-ml.github.io/">Home</a><a href="https://bit-ml.github.io/#research">Research</a><a href="https://bit-ml.github.io/#team">Team</a></nav><div class="content"><div><div class="Hero-lcEsqM dVPjPt"><h1 class="Hero__Heading-bTunXm ehEcQU">Engaging with the broader Machine Learning Community.<!-- --> </h1></div><div class="Home__SpecialtyContainer-iPQzcr jDndtc" id="research"><div class="Specialty__SpecialtyWrapper-cBNbYF dJHxnW"><div class="Specialty__SpecialtyPanel-hKIYws gNhSYZ"><h2 class="specItem Specialty__Heading-hJmugM faftxq">Computer Vision<!-- --> </h2><p class="specItem Specialty__Description-eZxbxJ hTCVgx">We tackle fundamental unsupervised learning approaches that we consider to be the key to true unconstrained learning, which best simulates how humans discover the surrounding world. We aim to combine the unsupervised visual perception with supervised cognitive video representation. We want to build systems that understand our world by only watching videos.
And we go further, teaching the system to describe, in natural language, the discovered elements.<!-- --> </p><p class="specItem Specialty__Team-iIpdBS kLZmb">Elena Burceanu, Iulia Duță, Ema Haller, Andrei Nicolicioiu, coordinated by Marius Leordeanu<!-- --> </p></div><div class="Specialty__ProjectsWrapper-glhYAT gGTWSb"><div class="Project-kErvvP bsszGK"><section class="Project__ProjectContent-ldPVeh dWtSnV"><h3 class="Project__Heading-cxYzLq hNRwWb">Unsupervised Object Tracking</h3><p class="Project__Text-jtyfJe gTCqVT">Object tracking is one of the first and most fundamental problems that has been addressed in computer vision. While it has attracted the interest of many researchers over several decades of computer vision, it is far from being solved.</p><p class="Project__Text-jtyfJe gTCqVT">The task is hard for many reasons. Difficulties could come from severe changes in object appearance, presence of background clutter and occlusions that might take place in the video.</p><p class="Project__Text-jtyfJe gTCqVT">The only ground-truth knowledge given to the tracker is the bounding box of the object in the first frame. Thus, without knowing in advance the properties of the object being tracked, the tracking algorithm must learn them on the fly. It must adapt correctly and make sure it does not jump toward other objects in the background. That is why the possibility of drifting to the background poses on of the main challenges in tracking.</p><ul class="Project__BibList-ewVyJd hQyaQE"><li class="Project__BibItem-kCJSqY dvaIyb"><a class="Project__BibLink-jsdCvg kxkinx" href="https://arxiv.org/abs/1804.01771" target="_blank"><span class="Project__BibAuthors-imCORI jpxIBs">E. Burceanu, M. Leordeanu</span>, Learning a Robust Society of Tracking Parts using Co-occurrence Constraints, <span class="Project__BibYear-dNTgUT jWtnNY">2018</span></a></li><li class="Project__BibItem-kCJSqY dvaIyb"><a class="Project__BibLink-jsdCvg kxkinx" href="https://arxiv.org/abs/1705.09602" target="_blank"><span class="Project__BibAuthors-imCORI jpxIBs">E. Burceanu, M. Leordeanu</span>, Learning a Robust Society of Tracking Parts, <span class="Project__BibYear-dNTgUT jWtnNY">2017</span></a></li></ul></section></div><div class="Project-kErvvP bsszGK"><section class="Project__ProjectContent-ldPVeh dWtSnV"><h3 class="Project__Heading-cxYzLq hNRwWb">Video Captioning</h3><p class="Project__Text-jtyfJe gTCqVT">Video captioning is the task of describing a video in natural language. It lies at the intersection of computer vision, natural language processing and machine learning requiring both high level visual comprehension and the ability to produce meaningful sentences. Our goal is to detect objects and events in a video and be capable of understanding the interactions between them in spatial and temporal dimensions.</p><p class="Project__Text-jtyfJe gTCqVT">We investigated multiple methods to analyze a video and extract information from it. To overcome limitations of the task and the available data, we design multiple models, to explore different video encoding strategies, to explore intermediate video-language representation and to investigate the gains brought by additional tasks and features. We propose a method for video captioning by selecting from the results of multiple encoder-decoder models. Our selection method based on consensus among multiple sentences is more likely to produce results with the same meaning as the video. We designed a methods that surpassed the state-of-the-art results on the challenging MSR-VTT dataset.</p><ul class="Project__BibList-ewVyJd hQyaQE"><li class="Project__BibItem-kCJSqY dvaIyb"><a class="Project__BibLink-jsdCvg kxkinx" href="https://arxiv.org/abs/1806.01954" target="_blank"><span class="Project__BibAuthors-imCORI jpxIBs">I. Duță, A. Nicolicioiu, V. Bogolin, M. Leordeanu</span>, Mining for meaning: from vision to language through multiple networks consensus, <span class="Project__BibYear-dNTgUT jWtnNY">2018</span></a></li></ul></section></div><div class="Project-kErvvP bsszGK"><section class="Project__ProjectContent-ldPVeh dWtSnV"><h3 class="Project__Heading-cxYzLq hNRwWb">Unsupervised learning of objects from video sequences</h3><p class="Project__Text-jtyfJe gTCqVT">We address an essential problem in computer vision, that of unsupervised foreground object segmentation in video, where a main object of interest in a video sequence should be automatically separated from its background. Video object segmentation and object discovery are strongly related tasks, but we tackle the problem from a fully unsupervised perspective, building object representations from raw video sequences. An efficient solution to this task would enable large-scale video interpretation at a high semantic level in the absence of the costly manual labeling.</p><p class="Project__Text-jtyfJe gTCqVT">We are focused on generating foreground object soft masks based on automatic selection and learning from highly probable positive features. We show that such features can be selected efficiently by taking into consideration the spatio-temporal appearance and motion consistency of the object in the video sequence. We also emphasize the role of the contrasting properties between the foreground object and its background. Our work is also focused on theoretically proving the properties of our unsupervised learning method, which under some mild constraints is guaranteed to learn the correct classifier even in the unsupervised case.</p><ul class="Project__BibList-ewVyJd hQyaQE"><li class="Project__BibItem-kCJSqY dvaIyb"><a class="Project__BibLink-jsdCvg kxkinx" href="https://arxiv.org/abs/1704.05674" target="_blank"><span class="Project__BibAuthors-imCORI jpxIBs">E. Haller, M. Leordeanu</span>, Unsupervised Object Segmentation in Video by Efficient Selection of Highly Probable Positive Features, <span class="Project__BibYear-dNTgUT jWtnNY">2017</span></a></li></ul></section></div></div></div><div class="Specialty__SpecialtyWrapper-cBNbYF dJHxnW"><div class="Specialty__SpecialtyPanel-hKIYws fDWUwD"><h2 class="specItem Specialty__Heading-hJmugM faftxq">Natural Language Processing<!-- --> </h2><p class="specItem Specialty__Description-eZxbxJ hTCVgx">A large amount of today&#x27;s data is stored in databases. Building AI tools that facilitate the access to knowledge requires processing of natural language and structured data. We focus on neural approaches for natural language interfaces to databases, in particular structure-aware and semi-supervised methods.<!-- --> </p><p class="specItem Specialty__Team-iIpdBS kLZmb">Florin Brad in collaboration with Traian Rebedea, Ionel Hosu, Radu Iacob<!-- --> </p></div><div class="Specialty__ProjectsWrapper-glhYAT gGTWSb"><div class="Project-kErvvP bsszGK"><section class="Project__ProjectContent-ldPVeh dWtSnV"><h3 class="Project__Heading-cxYzLq hNRwWb">Natural Language Interface to Databases</h3><p class="Project__Text-jtyfJe gTCqVT">Natural Language Interface to Databases (NLIDB) bridges the gap between technical and non-technical users by allowing the latter to query large amounts of structured data through the use of instructions written in natural language.</p><p class="Project__Text-jtyfJe gTCqVT">Despite long-standing research efforts, progress has been slow and widespread adoption has failed to pick up. Data-driven approaches have been hindered by the lack of large parallel corpora to train the models on, but recent datasets alleviate this problem. We seek to improve existing SEQ2SEQ models by leveraging syntax to guide the generation process and by using semi-supervised techniques to overcome the low parallel data regime.</p><ul class="Project__BibList-ewVyJd hQyaQE"><li class="Project__BibItem-kCJSqY dvaIyb"><a class="Project__BibLink-jsdCvg kxkinx" href="https://arxiv.org/abs/1707.03172" target="_blank"><span class="Project__BibAuthors-imCORI jpxIBs">F. Brad, R. Iacob, I. Hosu, T. Rebedea</span>, Dataset for a Neural Natural Language Interface for Databases (NNLIDB), <span class="Project__BibYear-dNTgUT jWtnNY">2017</span></a></li><li class="Project__BibItem-kCJSqY dvaIyb"><a class="Project__BibLink-jsdCvg kxkinx" href="#" target="_blank"><span class="Project__BibAuthors-imCORI jpxIBs">F. Brad, R. Iacob, I. Hosu, T. Rebedea</span>, Natural Language Interface for Databases Using a Dual-Encoder Model, <span class="Project__BibYear-dNTgUT jWtnNY">2018</span></a></li></ul></section></div></div></div><div class="Specialty__SpecialtyWrapper-cBNbYF dJHxnW"><div class="Specialty__SpecialtyPanel-hKIYws doMvKk"><h2 class="specItem Specialty__Heading-hJmugM faftxq">Reinforcement Learning<!-- --> </h2><p class="specItem Specialty__Description-eZxbxJ hTCVgx">Within the field of artificial intelligence reinforcement learning seems a natural setting for training agents that interact with the world we are living in. We engage in furthering the field by developing agents able to learn continuously in different environments. We are also investigating models sitting at the intersection of generative models and reinforcement learning.<!-- --> </p><p class="specItem Specialty__Team-iIpdBS kLZmb">Tudor Berariu, Florin Gogianu, Ștefan Postăvaru, collaborating with Andrei Nica<!-- --> </p></div><div class="Specialty__ProjectsWrapper-glhYAT gGTWSb"><div class="Project-kErvvP bsszGK"><section class="Project__ProjectContent-ldPVeh dWtSnV"><h3 class="Project__Heading-cxYzLq hNRwWb">Continual Learning</h3><p class="Project__Text-jtyfJe gTCqVT">Recent advances in machine learning are still limited to stationary tasks, but general purpose intelligence would require agents able to acquire knowledge in a continual manner dealing with interleaving tasks. Lifelong learning scenarios deal exactly with this problem: training agents on new tasks while preserving performance on old ones.</p><p class="Project__Text-jtyfJe gTCqVT">We are currently exploring memory based, optimization related and architectural methods to train neural models in lifelong learning scenarios.</p><ul class="Project__BibList-ewVyJd hQyaQE"></ul></section></div><div class="Project-kErvvP bsszGK"><section class="Project__ProjectContent-ldPVeh dWtSnV"><h3 class="Project__Heading-cxYzLq hNRwWb">Malmo AI Challenge</h3><p class="Project__Text-jtyfJe gTCqVT">The Microsoft Malmo AI Challenge proposed a time-extended stag hunt scneario build on top of the well-known Minecraft platform. In order to maximize its payoff in such a game an agent needs to predict the level of commitment to a collaborative strategy of the other player, decide on a specific plan and navigate through the environment to execute it.</p><p class="Project__Text-jtyfJe gTCqVT">Multi-agent setups pose additional optimization problems stemming from the non-stationarity of the training objective. Also, situated environments ask agents to learn dynamic strategies capable of dealing with sudden changes in the course of action (such as another playing abandoning the collaborative strategy).</p><p class="Project__Text-jtyfJe gTCqVT">We approached the contest by training agents through deep reinforcement learning techniques using recurrent neural networks for policies and for value estimation. We also added auxiliary loss functions (such as next reward, or next frame prediction) in order to complement the sparse reward signal.</p><p class="Project__Text-jtyfJe gTCqVT"> Our submission ranked second for the AI Summer School placement prize and third for the Microsoft Azure for Research Grant prize.</p><ul class="Project__BibList-ewVyJd hQyaQE"><li class="Project__BibItem-kCJSqY dvaIyb"><a class="Project__BibLink-jsdCvg kxkinx" href="./learning-maximize-return.pdf" target="_blank"><span class="Project__BibAuthors-imCORI jpxIBs">A. Nica, T. Berariu, F. Gogianu, A.M. Florea</span>, Learning to Maximize Return in a Stag Hunt Collaborative Scenario through Deep Reinforcement Learning, <span class="Project__BibYear-dNTgUT jWtnNY">2017</span></a></li></ul></section></div><div class="Project-kErvvP bsszGK"><section class="Project__ProjectContent-ldPVeh dWtSnV"><h3 class="Project__Heading-cxYzLq hNRwWb">Towards a generative Experience Replay</h3><p class="Project__Text-jtyfJe gTCqVT">Within the field of reinforcement learning with deep neural network estimators, this research proposal is concerned with investigating and then augmenting or replacing the Experience Replay mechanism found in most of the state-of-the art methods with shallow and flexible, action-conditional models of the environment working not in the pixel space but at the level of low-dimensional intermediate representations</p><ul class="Project__BibList-ewVyJd hQyaQE"></ul></section></div></div></div><div class="Specialty__SpecialtyWrapper-cBNbYF dJHxnW"><div class="Specialty__SpecialtyPanel-hKIYws looFfB"><h2 class="specItem Specialty__Heading-hJmugM faftxq">Cryptography<!-- --> </h2><p class="specItem Specialty__Description-eZxbxJ hTCVgx">Lattice-based cryptography is a great promise for post-quantum cryptography. We build advanced primitives whose security relies on the hardness of lattice problems.<!-- --> </p><p class="specItem Specialty__Team-iIpdBS kLZmb">Miruna Roșca, Radu Țițiu, coordinated by Damien Stehlé, Benoît Libert. Mădălina Bolboceanu<!-- --> </p></div><div class="Specialty__ProjectsWrapper-glhYAT gGTWSb"><div class="Project-kErvvP bsszGK"><section class="Project__ProjectContent-ldPVeh dWtSnV"><h3 class="Project__Heading-cxYzLq hNRwWb">Hardness of lattice problems</h3><p class="Project__Text-jtyfJe gTCqVT">Lattice-based cryptography is a great promise for post-quantum cryptography. It aims at harnessing the security of cryptographic primitives in the conjectured hardness of well-identiﬁed and well-studied algorithmic problems involving euclidean lattices. In order to build post-quantum cryptographic primitives based on lattices, we actually make use of some intermediate, more versatile problems, Learning With Errors (LWE) and Shortest Integer Solutions (SIS), which are provably at least as hard as classical lattice problems.</p><p class="Project__Text-jtyfJe gTCqVT">To obtain more efficient primitives, different structured variants of LWE and SIS have been introduced. We are interested in studying the hardness of all these problems, giving reductions between them and using them to build new cryptographic primitives.</p><ul class="Project__BibList-ewVyJd hQyaQE"><li class="Project__BibItem-kCJSqY dvaIyb"><a class="Project__BibLink-jsdCvg kxkinx" href="https://eprint.iacr.org/2017/628" target="_blank"><span class="Project__BibAuthors-imCORI jpxIBs">M. Rosca, A. Sakzad, D. Stehlé and R. Steinfeld</span>, Middle-Product Learning with Errors, <span class="Project__BibYear-dNTgUT jWtnNY">2017</span></a></li><li class="Project__BibItem-kCJSqY dvaIyb"><a class="Project__BibLink-jsdCvg kxkinx" href="https://eprint.iacr.org/2018/170" target="_blank"><span class="Project__BibAuthors-imCORI jpxIBs">M. Rosca, D. Stehlé and A. Wallet</span>, On the Ring-LWE and Polynomial-LWE Problems, <span class="Project__BibYear-dNTgUT jWtnNY">2018</span></a></li></ul></section></div><div class="Project-kErvvP bsszGK"><section class="Project__ProjectContent-ldPVeh dWtSnV"><h3 class="Project__Heading-cxYzLq hNRwWb">Cryptographic primitives from LWE</h3><p class="Project__Text-jtyfJe gTCqVT">My research project is concerned with building advanced cryptographic primitives, which mainly rely their security on the Learning With Errors problem (LWE). Together with my PhD advisor, Benoit Libert, we are currently working on improving known constructions of some Functional Encryption schemes.</p><p class="Project__Text-jtyfJe gTCqVT">Some Applications of this primitive: run learning algorithms on encrypted data; perform statistical tests on the sensitive encrypted data that one could find for instance in a hospital or in a bank.</p><ul class="Project__BibList-ewVyJd hQyaQE"><li class="Project__BibItem-kCJSqY dvaIyb"><a class="Project__BibLink-jsdCvg kxkinx" href="" target="_blank"><span class="Project__BibAuthors-imCORI jpxIBs">R. Țițiu, B.Libert, D. Stehlé</span>, Adaptively Secure Distributed PRFs from LWE, <span class="Project__BibYear-dNTgUT jWtnNY"></span></a></li><li class="Project__BibItem-kCJSqY dvaIyb"><a class="Project__BibLink-jsdCvg kxkinx" href="" target="_blank"><span class="Project__BibAuthors-imCORI jpxIBs">R. Țițiu, B.Libert, D. Stehlé</span>, Tight Security Proofs for GGM-like Lattice-Based PRFs, <span class="Project__BibYear-dNTgUT jWtnNY"></span></a></li></ul></section></div></div></div></div><div class="ResearchTeam-irfXYZ cFmWkc" id="team"><div class="Bio__BioBox-eznaTq fTTyYJ"><figure class="Bio__MediaFigure-kAfGvT vJsRg"><img src="./bio/elena_burceanu.jpg" alt=""/></figure><div class="Bio__MediaBody-igRzHf eruIzS"><h4 class="Bio__Heading-ftjIRz ebfeBw">Elena Burceanu<!-- --> </h4><p class="Bio-cTLmRQ iQvatf">My interest is in understanding videos in an unsupervised manner, currently working on object tracking for my PhD at University of Bucharest and Institute of Mathematics of the Romanian Academy. I have a strong background in Mathematics and Physics and I have finished my BSc in Computer Science and the MSc in Distributed Systems at University Politehnica Bucharest.<!-- --> </p><div class="Bio__ContactBox-bMmHPs fpCZLV"><a href="mailto:eburceanu@bitdefender.com">email</a><a href="https://github.com/ilarele">github</a><a href="https://twitter.com/ilarele">twitter</a></div></div></div><div class="Bio__BioBox-eznaTq fTTyYJ"><figure class="Bio__MediaFigure-kAfGvT vJsRg"><img src="./bio/tudor_berariu.jpg" alt=""/></figure><div class="Bio__MediaBody-igRzHf eruIzS"><h4 class="Bio__Heading-ftjIRz ebfeBw">Tudor Berariu<!-- --> </h4><p class="Bio-cTLmRQ iQvatf">I got my Master&#x27;s degree in Artificial Intelligence from University Politehnica of Bucharest after studying Computer Science there. I am currently a TA while pursuing a PhD in AI. My main research interest is in understanding systems capable of acquiring knowledge in a continual manner with a focus on the reinforcement learning setup. At Bitdefender I am currently studying various mechanisms for alleviating catastrophic forgetting in neural models.<!-- --> </p><div class="Bio__ContactBox-bMmHPs fpCZLV"><a href="mailto:tberariu@bitdefender.com">email</a><a href="https://github.com/tudor-berariu">github</a><a href="https://twitter.com/_tudor">twitter</a></div></div></div><div class="Bio__BioBox-eznaTq fTTyYJ"><figure class="Bio__MediaFigure-kAfGvT vJsRg"><img src="./bio/stefan_postavaru.jpg" alt=""/></figure><div class="Bio__MediaBody-igRzHf eruIzS"><h4 class="Bio__Heading-ftjIRz ebfeBw">Ștefan Postăvaru<!-- --> </h4><p class="Bio-cTLmRQ iQvatf">I came in the field of Machine Learning with a strong background in programming and mathematics, driven by an interest in the process of inference and systems capable of it. My main research focus are policies conditioned on given configurations and their ability of efficiently generalizing in unseen environments, in the context of Deep Reinforcement Learning.<!-- --> </p><div class="Bio__ContactBox-bMmHPs fpCZLV"><a href="mailto:spostavaru@bitdefender.com">email</a></div></div></div><div class="Bio__BioBox-eznaTq fTTyYJ"><figure class="Bio__MediaFigure-kAfGvT vJsRg"><img src="./bio/florin_brad.jpg" alt=""/></figure><div class="Bio__MediaBody-igRzHf eruIzS"><h4 class="Bio__Heading-ftjIRz ebfeBw">Florin Brad<!-- --> </h4><p class="Bio-cTLmRQ iQvatf">I am interested in neural generative models for natural language processing, especially for code generation. In particular, I am interested in leveraging discrete structure (syntax trees) to improve the expresiveness of the latent space and to guide the generation process.<!-- --> </p><div class="Bio__ContactBox-bMmHPs fpCZLV"><a href="mailto:fbrad@bitdefender.com">email</a></div></div></div><div class="Bio__BioBox-eznaTq fTTyYJ"><figure class="Bio__MediaFigure-kAfGvT vJsRg"><img src="./bio/iulia_duta.jpg" alt=""/></figure><div class="Bio__MediaBody-igRzHf eruIzS"><h4 class="Bio__Heading-ftjIRz ebfeBw">Iulia Duță<!-- --> </h4><p class="Bio-cTLmRQ iQvatf">I have a BSc in Computer Science and a MSc in Artificial Intelligence at the University of Bucharest. My research focuses on Computer Vision. I am particularly interested in developing techniques for a better understanding and representation of video scene. My current goal is to improve the quality of video descriptions using machine learning approaches.<!-- --> </p><div class="Bio__ContactBox-bMmHPs fpCZLV"><a href="mailto:iduta@bitdefender.com">email</a><a href="https://twitter.com/DutaIulia">twitter</a></div></div></div><div class="Bio__BioBox-eznaTq fTTyYJ"><figure class="Bio__MediaFigure-kAfGvT vJsRg"><img src="./bio/marius_leordeanu.jpg" alt=""/></figure><div class="Bio__MediaBody-igRzHf eruIzS"><h4 class="Bio__Heading-ftjIRz ebfeBw">Marius Leordeanu<!-- --> </h4><p class="Bio-cTLmRQ iQvatf">I am an Associate Professor (Senior Lecturer) at the University Politehnica of Bucharest and senior researcher at the Institute of Mathematics of the Romanian Academy. I am interested in the nature of intelligence, life and consciousness. In particular, my research focuses on computer vision, machine learning and robotics. At the university I teach the graduate level computer vision and robotics classes. I have received a Ph.D. in Robotics from Carnegie Mellon University in 2009 and Bachelor degrees in Mathematics and Computer Science from the City University of New York, 2003.<!-- --> </p><div class="Bio__ContactBox-bMmHPs fpCZLV"><a href="mailto:leordeanu@gmail.com">email</a></div></div></div><div class="Bio__BioBox-eznaTq fTTyYJ"><figure class="Bio__MediaFigure-kAfGvT vJsRg"><img src="./bio/florin_gogianu.jpg" alt=""/></figure><div class="Bio__MediaBody-igRzHf eruIzS"><h4 class="Bio__Heading-ftjIRz ebfeBw">Florin Gogianu<!-- --> </h4><p class="Bio-cTLmRQ iQvatf">Currently pursuing an MSc in Artificial Intelligence from University Politehnica of Bucharest after getting a BSc in Philosophy and graduating from an MSc in History &amp; Philosophy of Science. I have a broad interest in Reinforcement Learning topics and I am currently focusing on questions regarding sample efficiency in the context of model-free value-based methods with neural network estimators.<!-- --> </p><div class="Bio__ContactBox-bMmHPs fpCZLV"><a href="mailto:fgogianu@bitdefender.com">email</a><a href="https://github.com/floringogianu">github</a><a href="https://twitter.com/FlorinGogianu">twitter</a></div></div></div><div class="Bio__BioBox-eznaTq fTTyYJ"><figure class="Bio__MediaFigure-kAfGvT vJsRg"><img src="./bio/andrei_nicolicioiu.jpg" alt=""/></figure><div class="Bio__MediaBody-igRzHf eruIzS"><h4 class="Bio__Heading-ftjIRz ebfeBw">Andrei Nicolicioiu<!-- --> </h4><p class="Bio-cTLmRQ iQvatf">My focus in on deep learning methods for Computer Vision problems. I studied at University Politehnica of Bucharest, where I obtained a Bachelor&#x27;s degree and a Master&#x27;s degree in Artificial Inteligence. I began with studying some lower-mid level computer vision problems like occlusions regions segmentation and then I leaned over some higher level tasks, like multi-label classification in video, captioning in video, finding common representations between video and language.<!-- --> </p><div class="Bio__ContactBox-bMmHPs fpCZLV"><a href="mailto:anicolicioiu@bitdenfender.com">email</a></div></div></div><div class="Bio__BioBox-eznaTq fTTyYJ"><figure class="Bio__MediaFigure-kAfGvT vJsRg"><img src="./bio/emanuela_haller.jpg" alt=""/></figure><div class="Bio__MediaBody-igRzHf eruIzS"><h4 class="Bio__Heading-ftjIRz ebfeBw">Emanuela Haller<!-- --> </h4><p class="Bio-cTLmRQ iQvatf">I am a second year PhD student, co-supervised by Marius Leordeanu (Institute of Mathematics of the Romanian Academy) and Adina Magda Florea (University Politehnica of Bucharest). I have a BSc in Computer Science and a MSc in Artificial Intelligence, both from University Politehnica of Bucharest. My main focus is the problem of unsupervised learning and I am currently working on the task of unsupervised learning of objects from video sequences.<!-- --> </p><div class="Bio__ContactBox-bMmHPs fpCZLV"><a href="mailto:ehaller@gmail.com">email</a></div></div></div><div class="Bio__BioBox-eznaTq fTTyYJ"><figure class="Bio__MediaFigure-kAfGvT vJsRg"><img src="./bio/miruna_rosca.jpg" alt=""/></figure><div class="Bio__MediaBody-igRzHf eruIzS"><h4 class="Bio__Heading-ftjIRz ebfeBw">Miruna Roșca<!-- --> </h4><p class="Bio-cTLmRQ iQvatf">I am interested in post-quantum cryptography, with a focus on lattice-based solutions. I have a strong background in mathematics and I am currently a second year Phd student in cryptography at École Normale Supérieure de Lyon, working with Damien Stehlé on hardness of lattice problems over rings. More info about me here: http://perso.ens-lyon.fr/miruna.rosca/<!-- --> </p><div class="Bio__ContactBox-bMmHPs fpCZLV"><a href="mailto:mrosca@bitdefender.com">email</a></div></div></div><div class="Bio__BioBox-eznaTq fTTyYJ"><figure class="Bio__MediaFigure-kAfGvT vJsRg"><img src="./bio/madalina_bolboceanu.jpg" alt=""/></figure><div class="Bio__MediaBody-igRzHf eruIzS"><h4 class="Bio__Heading-ftjIRz ebfeBw">Mădălina Bolboceanu<!-- --> </h4><p class="Bio-cTLmRQ iQvatf">I obtained both my undergraduate and Master degrees in Mathematics from the University of Bucharest. My goal is to use my strong mathematical skills and experience in mathematical contests and olympiads to solve cryptographic challenges. I am interested in applications of lattices in cryptography, including lattice based homomorphic encryption schemes.<!-- --> </p><div class="Bio__ContactBox-bMmHPs fpCZLV"><a href="mailto:mbolboceanu@bitdefender.com">email</a><a href="https://twitter.com/molbozaur">twitter</a></div></div></div><div class="Bio__BioBox-eznaTq fTTyYJ"><figure class="Bio__MediaFigure-kAfGvT vJsRg"><img src="./bio/radu_titiu.jpg" alt=""/></figure><div class="Bio__MediaBody-igRzHf eruIzS"><h4 class="Bio__Heading-ftjIRz ebfeBw">Radu Țițiu<!-- --> </h4><p class="Bio-cTLmRQ iQvatf">I am in my second year as a PhD student in cryptography, under the supervision of Benoit Libert at ENS de Lyon. My focus is on lattice-based cryptography, which proposes promising cryptographic schemes in the eventuality that quantum algorithms could be implemented on quantum devices. Moreover, lattice-based cryptography enables the construction of some provably secure advanced cryptographic primitives including Identity Based Encryption, Attribute Based Encryption, Functional Encryption, Homomorphic Encryption.<!-- --> </p><div class="Bio__ContactBox-bMmHPs fpCZLV"><a href="mailto:rtitiu@bitdefender.com">email</a></div></div></div></div></div></div></div></div><script type="text/javascript">window.__CSS_CHUNKS__ = {}</script><script type="text/javascript">
    window.__routeInfo = {"path":"/","templateID":0,"sharedPropsHashes":{},"localProps":null,"allProps":{"specialties":[{"title":"Computer Vision","description":"We tackle fundamental unsupervised learning approaches that we consider to be the key to true unconstrained learning, which best simulates how humans discover the surrounding world. We aim to combine the unsupervised visual perception with supervised cognitive video representation. We want to build systems that understand our world by only watching videos.\nAnd we go further, teaching the system to describe, in natural language, the discovered elements.","people":"Elena Burceanu, Iulia Duță, Ema Haller, Andrei Nicolicioiu, coordinated by Marius Leordeanu","projects":[{"title":"Unsupervised Object Tracking","description":"Object tracking is one of the first and most fundamental problems that has been addressed in computer vision. While it has attracted the interest of many researchers over several decades of computer vision, it is far from being solved.\nThe task is hard for many reasons. Difficulties could come from severe changes in object appearance, presence of background clutter and occlusions that might take place in the video.\nThe only ground-truth knowledge given to the tracker is the bounding box of the object in the first frame. Thus, without knowing in advance the properties of the object being tracked, the tracking algorithm must learn them on the fly. It must adapt correctly and make sure it does not jump toward other objects in the background. That is why the possibility of drifting to the background poses on of the main challenges in tracking.","papers":[{"authors":"E. Burceanu, M. Leordeanu","title":"Learning a Robust Society of Tracking Parts using Co-occurrence Constraints","year":"2018","link":"https://arxiv.org/abs/1804.01771"},{"authors":"E. Burceanu, M. Leordeanu","title":"Learning a Robust Society of Tracking Parts","year":"2017","link":"https://arxiv.org/abs/1705.09602"}]},{"title":"Video Captioning","description":"Video captioning is the task of describing a video in natural language. It lies at the intersection of computer vision, natural language processing and machine learning requiring both high level visual comprehension and the ability to produce meaningful sentences. Our goal is to detect objects and events in a video and be capable of understanding the interactions between them in spatial and temporal dimensions.\nWe investigated multiple methods to analyze a video and extract information from it. To overcome limitations of the task and the available data, we design multiple models, to explore different video encoding strategies, to explore intermediate video-language representation and to investigate the gains brought by additional tasks and features. We propose a method for video captioning by selecting from the results of multiple encoder-decoder models. Our selection method based on consensus among multiple sentences is more likely to produce results with the same meaning as the video. We designed a methods that surpassed the state-of-the-art results on the challenging MSR-VTT dataset.","papers":[{"authors":"I. Duță, A. Nicolicioiu, V. Bogolin, M. Leordeanu","title":"Mining for meaning: from vision to language through multiple networks consensus","year":"2018","link":"https://arxiv.org/abs/1806.01954"}]},{"title":"Unsupervised learning of objects from video sequences","description":"We address an essential problem in computer vision, that of unsupervised foreground object segmentation in video, where a main object of interest in a video sequence should be automatically separated from its background. Video object segmentation and object discovery are strongly related tasks, but we tackle the problem from a fully unsupervised perspective, building object representations from raw video sequences. An efficient solution to this task would enable large-scale video interpretation at a high semantic level in the absence of the costly manual labeling.\nWe are focused on generating foreground object soft masks based on automatic selection and learning from highly probable positive features. We show that such features can be selected efficiently by taking into consideration the spatio-temporal appearance and motion consistency of the object in the video sequence. We also emphasize the role of the contrasting properties between the foreground object and its background. Our work is also focused on theoretically proving the properties of our unsupervised learning method, which under some mild constraints is guaranteed to learn the correct classifier even in the unsupervised case.","papers":[{"authors":"E. Haller, M. Leordeanu","title":"Unsupervised Object Segmentation in Video by Efficient Selection of Highly Probable Positive Features","year":"2017","link":"https://arxiv.org/abs/1704.05674","published":" In The IEEE International Conference on Computer Vision (ICCV)"}]}]},{"title":"Natural Language Processing","description":"A large amount of today's data is stored in databases. Building AI tools that facilitate the access to knowledge requires processing of natural language and structured data. We focus on neural approaches for natural language interfaces to databases, in particular structure-aware and semi-supervised methods.","people":"Florin Brad in collaboration with Traian Rebedea, Ionel Hosu, Radu Iacob","projects":[{"title":"Natural Language Interface to Databases","description":"Natural Language Interface to Databases (NLIDB) bridges the gap between technical and non-technical users by allowing the latter to query large amounts of structured data through the use of instructions written in natural language.\nDespite long-standing research efforts, progress has been slow and widespread adoption has failed to pick up. Data-driven approaches have been hindered by the lack of large parallel corpora to train the models on, but recent datasets alleviate this problem. We seek to improve existing SEQ2SEQ models by leveraging syntax to guide the generation process and by using semi-supervised techniques to overcome the low parallel data regime.","papers":[{"authors":"F. Brad, R. Iacob, I. Hosu, T. Rebedea","title":"Dataset for a Neural Natural Language Interface for Databases (NNLIDB)","year":"2017","link":"https://arxiv.org/abs/1707.03172","published":""},{"authors":"F. Brad, R. Iacob, I. Hosu, T. Rebedea","title":"Natural Language Interface for Databases Using a Dual-Encoder Model","year":"2018","link":"#","published":"To appear."}]}]},{"title":"Reinforcement Learning","description":"Within the field of artificial intelligence reinforcement learning seems a natural setting for training agents that interact with the world we are living in. We engage in furthering the field by developing agents able to learn continuously in different environments. We are also investigating models sitting at the intersection of generative models and reinforcement learning.","people":"Tudor Berariu, Florin Gogianu, Ștefan Postăvaru, collaborating with Andrei Nica","projects":[{"title":"Continual Learning","description":"Recent advances in machine learning are still limited to stationary tasks, but general purpose intelligence would require agents able to acquire knowledge in a continual manner dealing with interleaving tasks. Lifelong learning scenarios deal exactly with this problem: training agents on new tasks while preserving performance on old ones.\nWe are currently exploring memory based, optimization related and architectural methods to train neural models in lifelong learning scenarios.","papers":[]},{"title":"Malmo AI Challenge","description":"The Microsoft Malmo AI Challenge proposed a time-extended stag hunt scneario build on top of the well-known Minecraft platform. In order to maximize its payoff in such a game an agent needs to predict the level of commitment to a collaborative strategy of the other player, decide on a specific plan and navigate through the environment to execute it.\nMulti-agent setups pose additional optimization problems stemming from the non-stationarity of the training objective. Also, situated environments ask agents to learn dynamic strategies capable of dealing with sudden changes in the course of action (such as another playing abandoning the collaborative strategy).\nWe approached the contest by training agents through deep reinforcement learning techniques using recurrent neural networks for policies and for value estimation. We also added auxiliary loss functions (such as next reward, or next frame prediction) in order to complement the sparse reward signal.\n Our submission ranked second for the AI Summer School placement prize and third for the Microsoft Azure for Research Grant prize.","papers":[{"authors":"A. Nica, T. Berariu, F. Gogianu, A.M. Florea","title":"Learning to Maximize Return in a Stag Hunt Collaborative Scenario through Deep Reinforcement Learning","year":"2017","link":"./learning-maximize-return.pdf","published":""}]},{"title":"Towards a generative Experience Replay","description":"Within the field of reinforcement learning with deep neural network estimators, this research proposal is concerned with investigating and then augmenting or replacing the Experience Replay mechanism found in most of the state-of-the art methods with shallow and flexible, action-conditional models of the environment working not in the pixel space but at the level of low-dimensional intermediate representations","papers":[]}]},{"title":"Cryptography","description":"Lattice-based cryptography is a great promise for post-quantum cryptography. We build advanced primitives whose security relies on the hardness of lattice problems.","people":"Miruna Roșca, Radu Țițiu, coordinated by Damien Stehlé, Benoît Libert. Mădălina Bolboceanu","projects":[{"title":"Hardness of lattice problems","description":"Lattice-based cryptography is a great promise for post-quantum cryptography. It aims at harnessing the security of cryptographic primitives in the conjectured hardness of well-identiﬁed and well-studied algorithmic problems involving euclidean lattices. In order to build post-quantum cryptographic primitives based on lattices, we actually make use of some intermediate, more versatile problems, Learning With Errors (LWE) and Shortest Integer Solutions (SIS), which are provably at least as hard as classical lattice problems.\nTo obtain more efficient primitives, different structured variants of LWE and SIS have been introduced. We are interested in studying the hardness of all these problems, giving reductions between them and using them to build new cryptographic primitives.","papers":[{"authors":"M. Rosca, A. Sakzad, D. Stehlé and R. Steinfeld","title":"Middle-Product Learning with Errors","year":"2017","link":"https://eprint.iacr.org/2017/628","published":"In the proceedings of CRYPTO 2017, pages 283-297, Springer, 2017"},{"authors":"M. Rosca, D. Stehlé and A. Wallet","title":"On the Ring-LWE and Polynomial-LWE Problems","year":"2018","link":"https://eprint.iacr.org/2018/170","published":"In the proceedings of EUROCRYPT 2018, pages 146-173, Springer, 2018"}]},{"title":"Cryptographic primitives from LWE","description":"My research project is concerned with building advanced cryptographic primitives, which mainly rely their security on the Learning With Errors problem (LWE). Together with my PhD advisor, Benoit Libert, we are currently working on improving known constructions of some Functional Encryption schemes.\nSome Applications of this primitive: run learning algorithms on encrypted data; perform statistical tests on the sensitive encrypted data that one could find for instance in a hospital or in a bank.","papers":[{"authors":"R. Țițiu, B.Libert, D. Stehlé","title":"Adaptively Secure Distributed PRFs from LWE","year":"","link":"","published":"In submission"},{"authors":"R. Țițiu, B.Libert, D. Stehlé","title":"Tight Security Proofs for GGM-like Lattice-Based PRFs","year":"","link":"","published":""}]}]}],"people":[{"name":"Elena Burceanu","bio":"My interest is in understanding videos in an unsupervised manner, currently working on object tracking for my PhD at University of Bucharest and Institute of Mathematics of the Romanian Academy. I have a strong background in Mathematics and Physics and I have finished my BSc in Computer Science and the MSc in Distributed Systems at University Politehnica Bucharest.","img":"elena_burceanu.jpg","contact":{"mail":"eburceanu@bitdefender.com","twitter":"ilarele","github":"ilarele"}},{"name":"Tudor Berariu","bio":"I got my Master's degree in Artificial Intelligence from University Politehnica of Bucharest after studying Computer Science there. I am currently a TA while pursuing a PhD in AI. My main research interest is in understanding systems capable of acquiring knowledge in a continual manner with a focus on the reinforcement learning setup. At Bitdefender I am currently studying various mechanisms for alleviating catastrophic forgetting in neural models.","img":"tudor_berariu.jpg","contact":{"mail":"tberariu@bitdefender.com","twitter":"_tudor","github":"tudor-berariu"}},{"name":"Ștefan Postăvaru","bio":"I came in the field of Machine Learning with a strong background in programming and mathematics, driven by an interest in the process of inference and systems capable of it. My main research focus are policies conditioned on given configurations and their ability of efficiently generalizing in unseen environments, in the context of Deep Reinforcement Learning.","img":"stefan_postavaru.jpg","contact":{"mail":"spostavaru@bitdefender.com","twitter":"","github":""}},{"name":"Florin Brad","bio":"I am interested in neural generative models for natural language processing, especially for code generation. In particular, I am interested in leveraging discrete structure (syntax trees) to improve the expresiveness of the latent space and to guide the generation process.","img":"florin_brad.jpg","contact":{"mail":"fbrad@bitdefender.com","twitter":"","github":""}},{"name":"Iulia Duță","bio":"I have a BSc in Computer Science and a MSc in Artificial Intelligence at the University of Bucharest. My research focuses on Computer Vision. I am particularly interested in developing techniques for a better understanding and representation of video scene. My current goal is to improve the quality of video descriptions using machine learning approaches.","img":"iulia_duta.jpg","contact":{"mail":"iduta@bitdefender.com","twitter":"DutaIulia","github":""}},{"name":"Marius Leordeanu","bio":"I am an Associate Professor (Senior Lecturer) at the University Politehnica of Bucharest and senior researcher at the Institute of Mathematics of the Romanian Academy. I am interested in the nature of intelligence, life and consciousness. In particular, my research focuses on computer vision, machine learning and robotics. At the university I teach the graduate level computer vision and robotics classes. I have received a Ph.D. in Robotics from Carnegie Mellon University in 2009 and Bachelor degrees in Mathematics and Computer Science from the City University of New York, 2003.","img":"marius_leordeanu.jpg","contact":{"mail":"leordeanu@gmail.com","twitter":"","github":""}},{"name":"Florin Gogianu","bio":"Currently pursuing an MSc in Artificial Intelligence from University Politehnica of Bucharest after getting a BSc in Philosophy and graduating from an MSc in History & Philosophy of Science. I have a broad interest in Reinforcement Learning topics and I am currently focusing on questions regarding sample efficiency in the context of model-free value-based methods with neural network estimators.","img":"florin_gogianu.jpg","contact":{"mail":"fgogianu@bitdefender.com","twitter":"FlorinGogianu","github":"floringogianu"}},{"name":"Andrei Nicolicioiu","bio":"My focus in on deep learning methods for Computer Vision problems. I studied at University Politehnica of Bucharest, where I obtained a Bachelor's degree and a Master's degree in Artificial Inteligence. I began with studying some lower-mid level computer vision problems like occlusions regions segmentation and then I leaned over some higher level tasks, like multi-label classification in video, captioning in video, finding common representations between video and language.","img":"andrei_nicolicioiu.jpg","contact":{"mail":"anicolicioiu@bitdenfender.com","twitter":"","github":""}},{"name":"Emanuela Haller","bio":"I am a second year PhD student, co-supervised by Marius Leordeanu (Institute of Mathematics of the Romanian Academy) and Adina Magda Florea (University Politehnica of Bucharest). I have a BSc in Computer Science and a MSc in Artificial Intelligence, both from University Politehnica of Bucharest. My main focus is the problem of unsupervised learning and I am currently working on the task of unsupervised learning of objects from video sequences.","img":"emanuela_haller.jpg","contact":{"mail":"ehaller@gmail.com","twitter":"","github":""}},{"name":"Miruna Roșca","bio":"I am interested in post-quantum cryptography, with a focus on lattice-based solutions. I have a strong background in mathematics and I am currently a second year Phd student in cryptography at École Normale Supérieure de Lyon, working with Damien Stehlé on hardness of lattice problems over rings. More info about me here: http://perso.ens-lyon.fr/miruna.rosca/","img":"miruna_rosca.jpg","contact":{"mail":"mrosca@bitdefender.com","twitter":"","github":""}},{"name":"Mădălina Bolboceanu","bio":"I obtained both my undergraduate and Master degrees in Mathematics from the University of Bucharest. My goal is to use my strong mathematical skills and experience in mathematical contests and olympiads to solve cryptographic challenges. I am interested in applications of lattices in cryptography, including lattice based homomorphic encryption schemes.","img":"madalina_bolboceanu.jpg","contact":{"mail":"mbolboceanu@bitdefender.com","twitter":"molbozaur","github":""}},{"name":"Radu Țițiu","bio":"I am in my second year as a PhD student in cryptography, under the supervision of Benoit Libert at ENS de Lyon. My focus is on lattice-based cryptography, which proposes promising cryptographic schemes in the eventuality that quantum algorithms could be implemented on quantum devices. Moreover, lattice-based cryptography enables the construction of some provably secure advanced cryptographic primitives including Identity Based Encryption, Attribute Based Encryption, Functional Encryption, Homomorphic Encryption.","img":"radu_titiu.jpg","contact":{"mail":"rtitiu@bitdefender.com","twitter":"","github":""}}]},"siteData":{"title":"Bitdefender Machine Learning and Crypto Research Unit","description":"Bitdefender Machine Learning & Crypto Research Unit goals are to further the fields of machine learning and criptography while engaging with the international research community and to develop the local AI&ML scene by supporting and participating in local conferences, lecture and research groups.","tagline":"Engaging with the broader Machine Learning Community."}};</script><script defer="" type="text/javascript" src="https://bit-ml.github.io/bootstrap.eb3e92c3.js"></script><script defer="" type="text/javascript" src="https://bit-ml.github.io/templates/src/containers/Home.01bd1720.js"></script><script defer="" type="text/javascript" src="https://bit-ml.github.io/main.7c722bc8.js"></script></body></html>