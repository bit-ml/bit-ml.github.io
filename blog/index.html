<!DOCTYPE html><html lang="en"><head><title data-react-helmet="true">Latest Blog Posts | Bitdefender Research</title><meta data-react-helmet="true" name="description" content="List of all the recent blog posts by Bitdefender&#x27;s Machine Learning &amp; Crypto Research Unit."/><meta data-react-helmet="true" name="keywords" content="machine-learning,research,bitdefender,posts"/><meta data-react-helmet="true" property="og:title" content="Latest Blog Posts | Bitdefender Research"/><meta data-react-helmet="true" property="og:description" content="List of all the recent blog posts by Bitdefender&#x27;s Machine Learning &amp; Crypto Research Unit."/><meta data-react-helmet="true" property="og:site_name" content="https://bit-ml.github.io"/><meta data-react-helmet="true" property="article:tag" content="machine-learning"/><meta data-react-helmet="true" property="article:tag" content="research"/><meta data-react-helmet="true" property="article:tag" content="bitdefender"/><meta data-react-helmet="true" property="article:tag" content="posts"/><meta data-react-helmet="true" property="og:image" content="https://bit-ml.github.iohttps://bit-ml.github.io/tile.png"/><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"/><meta data-react-helmet="true" name="twitter:site" content="@Bitdefender"/><meta data-react-helmet="true" name="twitter:title" content="Latest Blog Posts | Bitdefender Research"/><meta data-react-helmet="true" name="twitter:description" content="List of all the recent blog posts by Bitdefender&#x27;s Machine Learning &amp; Crypto Research Unit."/><meta data-react-helmet="true" name="twitter:image" content="https://bit-ml.github.iohttps://bit-ml.github.io/tile.png"/><meta data-react-helmet="true" itemProp="description" content="List of all the recent blog posts by Bitdefender&#x27;s Machine Learning &amp; Crypto Research Unit."/><meta data-react-helmet="true" itemProp="keywords" content="machine-learning,research,bitdefender,posts"/><meta data-react-helmet="true" itemProp="image" content="https://bit-ml.github.iohttps://bit-ml.github.io/tile.png"/><link rel="preload" as="script" href="https://bit-ml.github.io/bootstrap.328c8020.js"/><link rel="preload" as="script" href="https://bit-ml.github.io/templates/src/pages/Blog.a209992a.js"/><link rel="preload" as="script" href="https://bit-ml.github.io/main.b0acd7e8.js"/><link rel="preload" as="style" href="https://bit-ml.github.io/styles.03c21b51.css"/><link rel="stylesheet" href="https://bit-ml.github.io/styles.03c21b51.css"/><meta charSet="UTF-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><link rel="apple-touch-icon" href="icon.png"/><style data-styled-components="goldxz gFasvY bLwfAq">
/* sc-component-id: sc-global-3682090152 */
html{line-height:1.15;-webkit-text-size-adjust:100%;} body{margin:0;} h1{font-size:2em;margin:0.67em 0;} hr{box-sizing:content-box;height:0;overflow:visible;} pre{font-family:monospace,monospace;font-size:1em;} a{background-color:transparent;-webkit-text-decoration:none;text-decoration:none;} abbr[title]{border-bottom:none;-webkit-text-decoration:underline;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted;} b,strong{font-weight:bolder;} code,kbd,samp{font-family:monospace,monospace;font-size:1em;} small{font-size:80%;} sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline;} sub{bottom:-0.25em;} sup{top:-0.5em;} figure{margin:0;} img{border-style:none;max-width:100%;} button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0;} button,input{overflow:visible;} button,select{text-transform:none;} button,[type="button"],[type="reset"],[type="submit"]{-webkit-appearance:button;} button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0;} button:-moz-focusring,[type="button"]:-moz-focusring,[type="reset"]:-moz-focusring,[type="submit"]:-moz-focusring{outline:1px dotted ButtonText;} fieldset{padding:0.35em 0.75em 0.625em;} legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal;} progress{vertical-align:baseline;} textarea{overflow:auto;} [type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0;} [type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{height:auto;} [type="search"]{-webkit-appearance:textfield;outline-offset:-2px;} [type="search"]::-webkit-search-decoration{-webkit-appearance:none;} ::-webkit-file-upload-button{-webkit-appearance:button;font:inherit;} details{display:block;} summary{display:list-item;} template{display:none;} [hidden]{display:none;} html{box-sizing:border-box;font-size:16px;} *,*::before,*::after{box-sizing:inherit;} body{font-family:"Roboto",Helvetica,Arial,sans-serif;font-weight:400;font-size:16px;padding:0;background:#FFF;} h1{display:block;margin:0.67em 0;}
/* sc-component-id: Navigation__Nav-qabwmo-0 */
.bLwfAq{width:100%;background:transparent;padding:0 1rem;font-family:"Roboto",Helvetica,Arial,sans-serif;text-align:right;} .bLwfAq a{padding:1rem;display:inline-block;font-style:normal;font-weight:500;line-height:23px;font-size:14px;text-align:right;text-transform:uppercase;color:#333;} .bLwfAq a:last-child{padding-right:0;} @media (min-width:64.0625em){.bLwfAq{padding:0 5rem;}}
/* sc-component-id: Featured__StyledButtonBack-xm4c49-5 */
.goldxz{position:absolute;top:50%;left:-5px;margin-left:10px;margin-top:-20px;width:40px;height:40px;padding:10px;background:none;border:none;outline:none;border-radius:40px;} @media (min-width:46.0625em){.goldxz{left:10px;width:70px;height:70px;padding:15px;}} @media (min-width:64.0625em){.goldxz{left:10px;width:70px;height:70px;padding:15px;}}
/* sc-component-id: Featured__StyledButtonNext-xm4c49-6 */
.gFasvY{position:absolute;top:50%;right:-5px;margin-right:10px;margin-top:-20px;width:40px;height:40px;padding:10px;background:none;border:none;outline:none;border-radius:40px;} @media (min-width:46.0625em){.gFasvY{right:10px;width:70px;height:70px;padding:15px;}} @media (min-width:64.0625em){.gFasvY{right:10px;width:70px;height:70px;padding:15px;}}</style><style data-styled-components="kcxHbP bLkZHz isDZEF">
/* sc-component-id: Blog__BlogWrapper-sc-1owziq9-0 */
.kcxHbP{margin:0 auto;max-width:720px;padding:0 1rem;} @media (min-width:64.0625em){.kcxHbP{padding-left:0 0 0 100px;}}
/* sc-component-id: Blog__Heading-sc-1owziq9-1 */
.bLkZHz{font-family:'Exo 2',sans-serif;margin:4rem 0;font-style:normal;font-weight:700;line-height:3rem;font-size:2.2rem;-webkit-letter-spacing:0.03em;-moz-letter-spacing:0.03em;-ms-letter-spacing:0.03em;letter-spacing:0.03em;color:#333333;}
/* sc-component-id: Blog__BlogList-sc-1owziq9-2 */
.isDZEF{padding-left:0;} .isDZEF>li{font-family:"Roboto",Helvetica,Arial,sans-serif;font-style:normal;font-weight:500;font-size:1.2rem;-webkit-letter-spacing:0.03em;-moz-letter-spacing:0.03em;-ms-letter-spacing:0.03em;letter-spacing:0.03em;list-style:none;margin-bottom:1rem;} .isDZEF>li> a{color:#333;} .isDZEF>li> a:hover{color:#E6212B;}</style></head><body><div id="root"><div class="content" data-reactroot=""><div><header><nav class="Navigation__Nav-qabwmo-0 bLwfAq"><a href="https://bit-ml.github.io/">Home</a><a href="https://bit-ml.github.io/#research">Research</a><a href="https://bit-ml.github.io/#team">Team</a></nav></header><main><section class="Blog__BlogWrapper-sc-1owziq9-0 kcxHbP"><h1 class="Blog__Heading-sc-1owziq9-1 bLkZHz">Recent Posts</h1><ul class="Blog__BlogList-sc-1owziq9-2 isDZEF"><li><a href="https://bit-ml.github.io/blog/post/bitdefender_at_eeml2019/">Bitdefender at EEML2019</a></li><li><a href="https://bit-ml.github.io/blog/post/recurrent-space-time-graph-neural-nets/">Recurrent Space-time Graph Neural Network</a></li><li><a href="https://bit-ml.github.io/blog/post/bitdefender_at_tmlss2018/">Bitdefender at TMLSS2018</a></li></ul></section></main></div></div></div><script type="text/javascript">window.__CSS_CHUNKS__ = {"main":"https://bit-ml.github.io/styles.03c21b51.css"}</script><script type="text/javascript">
    window.__routeInfo = {"path":"blog","templateID":1,"sharedPropsHashes":{"posts":"Z289y59"},"localProps":null,"allProps":{"posts":[{"title":"Bitdefender at EEML2019","slug":"bitdefender_at_eeml2019","authors":"Tudor Berariu","categories":"event","galleries":"eeml2019_pictures:6","featured_img":"/galleries/eeml2019_pictures/full_house.jpg","date":"September-20-2019","contents":"<p>This summer Bitdefender’s Machine Learning Research Team participated in the\nsecond edition of the Eastern European Machine Learning Summer School, this\nyear’s highlight event for our fast growing machine learning community in\nRomania.</p>\n<p><img src=\"/galleries/eeml2019_pictures/group.jpg\" alt=\"eeml2019_group_photo\" title=\"EEML2019 group photo.\"></p>\n<h2 id=\"what-is-eeml-\">What is EEML?</h2>\n<p>The EEML Summer School gathers top researchers from universities and\ncompanies, offering an intensive week full of lectures and practicals to\nparticipants ranging from undergrad students to post-doc researchers.</p>\n<p>The summer school was successful in its mission to connect Eastern Europe\nwith the rest of the world, welcoming attendees from 42 different countries.\nBeing true to the schools values on inclusiveness, women represented almost a\nthird of the participants, more than the usual ratio encountered in STEM.</p>\n<p>Furthermore, at the national level, EEML offered the chance to meet and\nstrengthen the collaboration between research hubs in Iași, Cluj-Napoca,\nTimișoara, and Brașov.</p>\n<blockquote>\nI like the fact that, although the school grows visibly in size, you still\nhave a chance to talk and share opinions with speakers and other\nparticipants.\n<footer>\nIulia Duță, Bitdefender\n</footer>\n</blockquote>\n\n\n<p>Bringing everyone together for a full week makes EEML an ideal place to\nexchange ideas with others working on similar topics, to draw inspiration\nfrom others’ approach to their problems, and this adds a valuable extra to\nthe overall learning experience.</p>\n<blockquote>\nIt's been more than two months since I participated at EEML but the ideas\nfloated there and the relationships I started still seem highly relevant to\nme - as should be the case for any good summer school. I fondly remember the\nthings I learned from David Nagy (<a\nhref=\"https://twitter.com/dvgnagy\">@dvgnagy</a>) on Bayesian reasoning, the\ndiscussions I had with Rob (<a\nhref=\"https://twitter.com/RobertTLange\">@RobertTLange</a>) on RL, multi-agent\nsystems and much more or the reading suggestions on causal inference I got\nfrom Jeroen Berrevoets (<a\nhref=\"https://twitter.com/J_Berrevoets\">@J_Berrevoets</a>). EEML also\nfacilitated starting a research collaboration with Błażej Osiński and Maciej\nWołczyk after discussing it over some beers.\n<footer>\nFlorin Gogianu, Bitdefender\n</footer>\n</blockquote>\n\n\n<h2 id=\"bitdefender-among-organizers\">Bitdefender among organizers</h2>\n<p>EEML’s mission was laid out by a group of successful romanian researchers\nthat wanted to ensure eastern european talent pool gets access to the same\nresources as the more established academic centers in the western world.\nDoina Precup, Răzvan Pașcanu, and Viorica Pătrăucean were the leading\norganizers of the summer school, and their dedication made everything\npossible.</p>\n<p>Bitdefender was one of the Gold Sponsors of EEML proving its commitment to\nadvance the local research community and invest in local education. Beside\nthat, our own Elena Burceanu was one of the organizers of EEML, putting a lot\nof time and effort into making sure that every little detail will happen like\nclockwork.</p>\n<p><img src=\"/galleries/eeml2019_pictures/bitdefender_booth.jpg\" alt=\"bitdefender_booth\" title=\"Elena and Ștefan at the Bitdefender booth.\"></p>\n<p>EEML is a huge event so it was all hands on deck. Therefore we put the\nvolunteer yellow shirts on, took a deep breath, a sip of coffee and joined\nthe efforts. Our colleagues helped participants finding their way from the\nairport to the accommodation, prepared the welcome bags, they made sure every\nvideo projector works, and that there are spare batteries for the microphones\nin the lecture room.</p>\n<p><img src=\"/galleries/eeml2019_pictures/volunteers.jpg\" alt=\"eeml_volunteers\" title=\"EEML volunteers welcoming the participants.\"></p>\n<p>The summer school kicked off with a humorous presentation about the Romanian\nculture from our own Florin Brad. That moment provided everyone with the\nenergy to go through the full week.</p>\n<!-- ![florin_brad](/galleries/eeml2019_pictures/florin_brad.jpg \"Florin Brad giving the tour.\") -->\n\n<p><img src=\"/galleries/eeml2019_pictures/florin_brad.jpg\" alt=\"Florin Brad\"\n    title=\"Florin Brad giving the tour.\" height=520 /></p>\n<p>In Florin’s own words:</p>\n<blockquote>\nThis year I held a five minute presentation about Romania during the opening\nof the summer school. They say the best way to learn something is to explain\nit to other people, so I hope people have learned one or two things about our\ncountry (because I sure have).\n<footer>\nFlorin Brad, Bitdefender\n</footer>\n</blockquote>\n\n\n<h2 id=\"the-lectures\">The lectures</h2>\n<p>The lectures at EEML covered a broad range of topics in Machine Learning\naiming to both build the theoretical foundations for the newcomers and also\nhint to the research frontiers in the domain.</p>\n<p>Furthermore, the diverse background of the speakers enabled a wide variety of\nlectures, ranging from pragmatic descriptions of the latest research results\nto theoretical crash courses in the different areas covered by the summer\nschool.</p>\n<h2 id=\"posters\">Posters</h2>\n<p>EEML participants were encouraged to present their current work in a poster\nsession that spanned over two evenings (actually well into the night). That\nwas a great opportunity for them to get feedback from the seniors.</p>\n<blockquote>\nIt was a great opportunity to present my work at EEML, getting a chance to\nshare opinions with amazing people with varied expertise in computer vision.\nThis experience had a positive impact and helped me shape my next research\nsteps as many discussions brought a new perspective over my work.\n<footer>\nEmanuela Haller, Bitdefender\n</footer>\n</blockquote>\n\n<p>Our team unveiled three internal research efforts. Iulia Duță and Andrei\nNicolicioiu presented their novel recurrent space-time graph neural networks\nfor video understanding (also accepted at NeurIPS!!!). Emanuela Haller\ndiscussed her work on spacetime graph optimization for video object\nsegmentation. Florin Gogianu introduced his idea to use uncertainty to\nprioritize past experiences for training agents through reinforcement\nlearning.</p>\n<blockquote>\nEEML also provided me with the opportunity of presenting my work on\nBayesian-inspired prioritization measures for the Experience Replay buffer\nduring one of the two poster sessions. It was actually my first\nconference-like poster session I attended so it was a rather interesting\nexperience. I received some great suggestions from Diana Borsa which might\nhelp me polish this research further and also got some follow-up questions\nfrom the people I met there. Somehow I also got one of the Best Poster Awards\nand that wrapped-up nicely the great experience I had attending EEML.\n<footer>\nFlorin Gogianu, Bitdefender\n</footer>\n</blockquote>\n\n\n<h2 id=\"teaching-assistants\">Teaching assistants</h2>\n<p>EEML practicals were challenging applications of the theory discussed during\nthe lectures. The subjects were quite diverse covering Image classification,\nreinforcement learning, recurrent neural nets for language models, or\ngenerative models such as variational autoencoders. The teaching assistants\nhad the job to guide the participants into solving this tasks, and leave the\nsummer school with a consistent experience in training deep neural models\nusing Tensorflow. The TAs were researchers from prestigious universities, and\ncompanies such as DeepMind, and Bitdefender.</p>\n<blockquote>\nFor me, it was quite a different perspective this time, as I join the summer\nschool as a teaching assistant, an attribution that I loved to hold as it\ngave me the opportunity, besides captivating lectures held by top researchers\nall over the world, to interact more with participants and other TAs. It was\na great mix of receptive students, awesome devoted colleagues and a strong\nteam behind all the labs that prepares everything to be fun and valuable._\n<footer>\nIulia Duță, Bitdefender\n</footer>\n</blockquote>\n\n\n<p>Our own colleagues, some of which are also teaching at University Politehnica\nof Bucharest or University of Bucharest (Iulia, Florin, Andrei, Ștefan, Ema,\nTudor) got involved in guiding the participants through the new stuff in each\nlaboratory.</p>\n<blockquote>\nI am a teaching assistant at the university, but here it was way more\nchallenging given the hard topics and the smart and enthusiastic people\nattending. Brilliant researchers were also acting as teaching assistants and\nI really appreciate interacting with them during and before the labs. It was\nvery interesting to see how other TAs explain the topics they are experts\non. \n<footer>\nAndrei Nicolicioiu, Bitdefender\n</footer>\n</blockquote>\n\n\n<h2 id=\"epilogue\">Epilogue</h2>\n<p>EEML was a huge opportunity for Bucharest to join and interact with the\nrelevant actors in the machine learning community. Bitdefender is proud to be\nso deeply involved in bringing this event to our city.</p>\n<blockquote>\nFacilitating new relations between like-minded researchers at the beginning\nof their careers is not the only thing making EEML great. I felt I gained a\nlot by participating or assisting in discussions with researchers like Răzvan\nPașcanu, Doina Precup, Andrei Rusu or Akata Zeynep. Simply hanging around\nthese people and hear them discussing any topic for 20 minutes can leave you\nwith tons of insights and problem formulations they've deeply thought about\nand to which you could not have access to otherwise.\n<footer>\nFlorin Gogianu, Bitdefender\n</footer>\n</blockquote>\n\n\n"},{"title":"Recurrent Space-time Graph Neural Network","slug":"recurrent-space-time-graph-neural-nets","authors":"Iulia Duță, Andrei Nicolicioiu","categories":"blog","featured_img":"/galleries/rstg_pictures/featured_graph_nets.jpg","date":"November-26-2019","contents":"<!-- featured_img: \"/galleries/rstg_pictures/side_banner5.png\" -->\n\n<p>We introduce in this post our <strong>Recurrent Space-time Graph Neural Network</strong> (RSTG) architecture designed for learning video representation and  especially suited for tasks heavily relying on interactions.</p>\n<p>Let’s begin by considering the key components of video understanding that our method should include. Being able to detect and localise objects is the first crucial thing that we need to do, then we should combine them in various ways to create complex scenes. <em>Whole is greater than the sum of its parts</em>, but is it always true, and what are the conditions of this happening? </p>\n<p>In order to form a greater whole, objects must have some kind of connections between them. A set of random objects that do not correlate in any way doesn’t bring much additional information.  Entities could form different types of connections, they could be semantically related or they could be related by their physical position in space and in time. These kinds of relations happen in both image and video, with the time dimension of the video adding more difficulty, greatly increasing the amount and complexity of interactions happening in the scene.</p>\n<p>Let’s define the kind of interaction happening in the video by examining a few examples.</p>\n<!-- ![eeml2019_group_photo](/galleries/rstg_pictures/rstg.gif \"RSTG architecture.\") -->\n<p><img src=\"/galleries/rstg_pictures/interaction_videos.gif\" alt=\"eeml2019_group_photo\" title=\"Temporal interaction.\"></p>\n<p>Above, the yellow car and the grass appear together during the whole video, but the event <em>the car crosses the line</em> is characterized by a specific interaction. We call those types of interactions happening at the frame level <strong>spatial</strong> interactions. On the other hand, the event <em>the yellow car overtakes the red car</em> can not be captured from a single frame as it only makes sense across time. We call this <strong>temporal</strong> interactions.</p>\n<p>The entities that interact shouldn’t necessary be close to each other, either in time or in space, since there could also exist <strong>long-range</strong> interactions. In the above picture, the man and the moon are connected regardless of their distance in the image.</p>\n<h2 id=\"analysing-videos-with-spatio-temporal-graph-models\">Analysing videos with spatio-temporal graph models</h2>\n<p>Models commonly used in Computer Vision, based on convolutional networks, implicitly capture interactions in both space and time dimension, but they are biased towards local, short-range relations. </p>\n<p>We propose a method designed to explicitly model relations and that is capable of capturing long range connections. Our model fits into the broader category of <strong>graph neural networks</strong> (GNNs). We process the video imposing a graph structure in order to explicitly model interactions between different entities. GNNs usually send  messages between each pair of  nodes, thus easily modeling binary interactions. Higher order interactions could be achieved by multiple such message-passing iterations. </p>\n<p>The animation below illustrates the main components of our model.</p>\n<!-- ![eeml2019_group_photo](/galleries/rstg_pictures/rstg.gif \"RSTG architecture.\") -->\n\n<img src=\"/galleries/rstg_pictures/rstg.gif\" alt=\"RSTG architecture.\"    title=\"RSTG architecture.\" max-width=130% width=3584   />\n\n\n<p>At each time step, we <strong>create nodes</strong> by extracting information from features given by a convolutional network. Each node corresponds to a different fixed region of the input and we connect them if they come from neighbouring regions or if they overlap, as shown in the figure above. Using multiple scales helps us to capture entities of different sizes  and also to connect distant regions more easily.</p>\n<p>For the two types of interactions described above, we create two separate processing components. For each time step, we design a <strong>space processing</strong> stage to model the spatial interaction by iteratively  message-passing. This involves 3 steps: sending messages between each pair of connecting nodes, aggregating the messages received at each node by an attention mechanism and updating each node based on the current state and the aggregated message. We design a <strong>time processing</strong> stage to model temporal interactions by sending messages in time, only between the states of the same node, in a recurrent fashion. More specifically, at each time step, each node receives information only from its corresponding state from the previous time step.</p>\n<p>To model more expressive spatio-temporal interactions and to give it the ability to reason about all the information in the scene, with knowledge about past states, we alternate the two processing stages, as shown in the animation below.</p>\n<p><img src=\"/galleries/rstg_pictures/rstg_stages.gif\" alt=\"rstg_stages\" title=\"Alternative Space and Time Processing Stages.\"></p>\n<p>By having multiple space iteration, we go from local to more global processing, modeling interactions happening between an increasing number of entities situated at increasingly longer distances. We want to have some temporal information at every such steps, in order to model interactions that takes into account the history.  In order to combine the same kind of features from different time steps, we only connect the k-th spatial stage with the k-th stage from the previous step as shown in the animation.</p>\n<p>We can pool all the nodes into a vector representation used for the final prediction or we could project back each node into its initial corresponding region, forming a feature volume with the same size as the graph input so that our model could be used as a module inside any other architecture.</p>\n<!-- ![florin_brad](/galleries/eeml2019_pictures/florin_brad.jpg \"Florin Brad giving the tour.\") -->\n\n<!-- <img src=\"/galleries/eeml2019_pictures/florin_brad.jpg\" alt=\"Florin Brad\"    title=\"Florin Brad giving the tour.\" height=520 /> -->\n\n\n\n\n<!-- ![eeml_volunteers](/galleries/eeml2019_pictures/florin_brad.jpg \"EEML volunteers welcoming the participants.\") -->\n\n\n\n\n<h2 id=\"synthetic-dataset\">Synthetic Dataset</h2>\n<p>Training on a large real world dataset takes a lot of time and computational resources and could also involves hidden biases that could mask the capabilities of a model. For example, because of an unbalanced dataset, the activity of skiing could be detected only from the context of a snowy scene.  Thus, we designed a synthetic dataset where the complexity comes from the necessity of explicitly modeling spatial and temporal interactions but in a cleaner, simpler environment.</p>\n<img src=\"/galleries/rstg_pictures/digits.gif\" alt=\"SyncMNIST\"    title=\"SyncMNIST\" width=600   />\n\n<p>Our <a href=\"https://github.com/IuliaDuta/RSTG\">SyncMNIST</a> datasets involves videos where the goal is to detect a pair of digits that move synchronous among others that move randomly. On this dataset, we validate our key design choices by conducting ablation studies. </p>\n<p>We show that it is important to have both processing stages, each having its own set of parameters and to have multiple alternating temporal and spatial stages. We note that our model is also improved by incorporating positional embeddings in the node features. Our final model, that includes all these elements  surpasses strong models such as I3D and Non-Local.</p>\n<h2 id=\"real-world-experiments\">Real world experiments</h2>\n<p><img src=\"/galleries/rstg_pictures/smt-smt2.gif\" alt=\"smt_example\" title=\"a) Failing to put something into something because something does not fit b) pretending to put something into something\"></p>\n<p>To validate the capability of our model, we evaluate the RSTG model on a human-object interaction dataset - <a href=\"https://20bn.com/datasets/something-something/v1\">Something-Something v1</a> . This dataset contains fine-grained actions, that can not be distinguished solely on their context, where the interactions between entities across the entire video are essential.  We compare against top-models in the literature and obtain state of the art results.</p>\n<p><img src=\"/galleries/rstg_pictures/chart.svg\" alt=\"results\" title=\"Something-Something Results\"></p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>We hope that graph based methods would be more broadly  adopted in visual domain tasks, especially those where interactions play a crucial role and that our methods brings more evidence that such models could be successfully applied in such tasks. </p>\n<p>Our proposed RSTG model, seen as a spatio-temporal processing module, could be used for other various problems. Key aspects proved by our experiments,  such as the creation of a graph structure from convolutional features or the coupled but factorised time and space processing could be integrated into other models.</p>\n<p>We released the code of our models and SyncMNIST dataset\n<a\nhref=\"https://github.com/IuliaDuta/RSTG\">here</a>.</p>\n<p>More details  about our work could be found in our\n<a\nhref=\"https://papers.nips.cc/paper/9444-recurrent-space-time-graph-neural-networks\">paper</a>: </p>\n<p>Andrei Nicolicioiu, Iulia Duta, Marius Leordeanu, <em>Recurrent Space-time Graph Neural Networks</em>,   In Advances in neural information processing systems (<em>NeurIPS 2019</em>).</p>\n"},{"title":"Bitdefender at TMLSS2018","slug":"bitdefender_at_tmlss2018","authors":"Elena Burceanu","categories":"event","galleries":"tmlss2018_posters:5, tmlss2018_pictures:5","featured_img":"/galleries/tmlss2018_pictures/salina_1.jpg","date":"August-2-2018","contents":"<p><strong>Bitdefender’s Machine Learning Unit</strong> participated with eight of its members\nat the first edition of the <a href=\"https://tmlss.ro/\">Transylvania Machine Learning Summer\nSchool</a> that took place at the end of July 2018 in\nCluj-Napoca.</p>\n<p>The organizers are well known DeepMind figures (and also Romanians :D), Doina\nPrecup, Razvan Pascanu and Viorica Patraucean and RIST institute from Cluj -\nLuigi Malago and Razvan Florian.</p>\n<p>The motivation for the Summer School was to facilitate new relations between\nthe Machine Learning research community of Eastern Europe with the rest of\nthe world by encouraging collaboration between students and researchers\nfrom Eastern Europe with other more developed research centers and also by\noffering more accessible fees to the school attendees.</p>\n<p>Since the school had excellent lecturers, the competition was tough. From over\n800 participants, only 100 were selected to participate and to present a poster\nwith his/hers research results or work in progress. The diversity of the\nparticipants was a keypoint in the selection, roughly half of the\nparticipants were Romanians.</p>\n<p>Some words about the schedule. Each day we attended to several lectures, some\nof them introductory, other more advanced. At the end of the day we had lab\nsessions on Math, Computer Vision, Language, Generative Models, Unsupervised\nLearning and Reinforcement Learning. At the poster sessions, each of us had up\nto 4h30 to present the poster to anyone interested walking by. A detailed\nprogram can be found here tmlss.ro/programme.php.</p>\n<p>Even though there were six full and exhausting days, our team really enjoyed it\nand tried to get the most out of the lecturers and from the interactions with\nthe participants and the lecturers. Bitdefender was very well represented and\nwe came back home inspired and eager to continue our research.  More, we also\ngot a Best Poster award for Computer Vision (yey!).</p>\n<p>Actually our team enjoyed this experience so much that some of them decided to\ngive an individual account of some of the highlights of TMLSS2018 and the\nlectures that gave them a long lasting impression.</p>\n<p><strong>Tudor Berariu</strong>:</p>\n<p><em>The Transylvanian Machine Learning Summer School represents the perfect venue\nfor all who are interested in pursuing a research career in machine learning.\nFor those that are yet unfamiliar with the field TMLLSS gives the chance to\ngrasp the fundamental theory of a broad set of core topics. At the same time,\nthe more experienced participants are being offered a glimpse of the top\nresearchers’ reflections on the open problems in the field. All in all, Cluj\nwas the place to be this July if interested in machine learning.</em></p>\n<p><em>Amidst all those captivating lectures spanned over six days one caught my eye\nin particular: <strong>Ulrich Paquet’s</strong> introduction to Variational Autoencoders.\nAlthough I held some lectures on the topic myself in the past years, I found\nUlrich’s <a href=\"https://youtu.be/xTsnNcctvmU\">presentation</a> remarkable for its\nconcise, visual, extremely clear, while at the same time strongly theoretical\nelucidation of what and how VAEs do achieve. I wish my lectures were half as\ngood as his.</em></p>\n<p><em>Later that day, while visiting the boring salt mine near Turda, I also had the\nchance to chat with Ulrich and ask him a few questions regarding generative\nmodels, especially Boltzmann Machines. His exact words <em>Do not give up research\non Boltzmann Machines.</em> convinced me to recommence my efforts on training\ndifferent flavours of energy-based models to structure knowledge in\nreinforcement learning setups.</em></p>\n<p><strong>Iulia Duță</strong>:</p>\n<p><em>The main focus of the summer school was to popularize the machine learning\nfields in Eastern Europe, so the lectures’ content was a mixture of\nintroductory and more advanced topics. Knowing that beforehand, I arrived in\nCluj both with the goal of capturing speaker’s intuitions on fundamental\nconcepts in machine learning and insights on open, more recent challenges in\nthe field.</em></p>\n<p><em>One of the lectures that I remarked as being well structured and\ncreated exactly for this purpose was <strong>Dumitru Erhan’s</strong> presentation: “Computer\nVision: Way  Beyond  Classification”. He build the lecture incrementally, from\na classical computer vision problem (Object Detection) to a much hotter topic\n<a href=\"https://arxiv.org/abs/1612.05424\">Domain Adaptation</a>. Both of them were\npresented in terms of how the field evolved over time, highlighting advantages\nand disadvantages of each approaches. While the first part addresses a common\nproblem for computer vision researchers, Domain adaptation is a topic\nextremely important for all machine learning subfields, being a worth studying\nopen problem. So besides useful knowledge and interactions, TMLSS showed us a\nglimpse of novel research and a long bibliography to follow.</em></p>\n<p><strong>Andrei Nicolicioiu</strong>:</p>\n<p><em>The lecture that impressed me the most was the one about Graph Networks\npresented by <strong>Răzvan Pașcanu</strong>. He showed intuitions about the priors existing\nin deep networks and the need for models better suited for domains having\nstrong <a href=\"http://arxiv.org/abs/1806.01261v2\">relational priors</a>. We were\npresented in a unified way different views of the domain from general graph\nnetworks to simpler graph convolutional architectures, showing the usefulness\nof relations both in problems involving data with a more obvious graph\nstructure as molecules and in unexpected places like the interactions of\nmemories in a recurrent model. The presentation certainly inspired me to study\nmore about these approaches and how can they be applied in my research.</em></p>\n<p><strong>Dana Axinte</strong>:</p>\n<p><em>Neural networks, gradients, posters, enthusiasm, magic. These are some of the\nsettings of the first Transylvanian Machine Learning Summer School held in\nCluj, Romania. Looking through the schedule and speakers, I expected the school\nto be strong and that I would have the chance to settle new concepts while I\nwould engage with other participants with different backgrounds, but same\ninterests.</em></p>\n<p><em>I liked the balance between theoretically focused lectures and the ones that\npresented the industry usage of those concepts. Such pair of lectures that I\nparticularly appreciated were the ones by <strong>Doina Precup</strong> who took a\nprogressive approach in presenting value-based methods with function\napproximation for reinforcement learning and the one of <strong>Raia Hadsell</strong> who\nshowed how deep reinforcement learning can be applied into\n<a href=\"http://arxiv.org/abs/1610.04286v2\">robotics</a>, with the challenges that exists\nand the possible <a href=\"http://arxiv.org/abs/1804.00168v2\">solutions</a>.</em></p>\n<p><em>One of the parts of the summer school that I especially enjoyed was the panel\nsession where some lecturers shared their opinion on different interesting\ntopics. The reproducibility of experiments, the future of AI research and\nadvices to increase the local AI ecosystems, as what could be the involvement\nof governments, companies and teachers were few of the issues discussed. There\nwere no hype or buzzwords, but the lecturers were people who know today’s\nlimitations, needs and questions and get things done step by step, with an\nengineering mindset. A fundamental feeling with which I left is that it is not\nonly about learning, but sharing the experience and knowledge gained to empower\nothers to create and to strengthen the community and motivation.</em></p>\n<h3 id=\"conclusions\">Conclusions</h3>\n<p>It was only the first edition, but every detail was at a very high standard. In\nthe last days, we presented with Traian Rebedea the advantages of having the\nnext Summer School edition here in Bucharest. Looking forward to TMLSS2019 :)</p>\n"}]},"siteData":{"title":"Bitdefender Machine Learning & Crypto Research Unit","description":"Bitdefender Machine Learning & Crypto Research Unit goals are to further the fields of machine learning and criptography while engaging with the international research community and to develop the local AI&ML scene by supporting and participating in local conferences, lecture and research groups.","tagline":"Engaging with the broader Machine Learning Community.","tags":["machine-learning","research","bitdefender"]}};</script><script defer="" type="text/javascript" src="https://bit-ml.github.io/bootstrap.328c8020.js"></script><script defer="" type="text/javascript" src="https://bit-ml.github.io/templates/src/pages/Blog.a209992a.js"></script><script defer="" type="text/javascript" src="https://bit-ml.github.io/main.b0acd7e8.js"></script></body></html>